Week 4 (about 2 days before deadline and submission day)

This week I focused on additional model comparisons, documentation, and making the project reproducible. I added an extra experiment with MobileNetV2 as another small architecture. I modified its classifier to output 10 classes and trained it on CIFAR-10 for 5 epochs. I computed per-class precision and recall for MobileNetV2 and compared its overall accuracy and cat metrics to the baseline and fine-tuned ResNet-18. MobileNetV2 reached similar overall accuracy but did not beat the class-weighted fine-tuned ResNet-18 on the cat class.

I also implemented a transfer-learning experiment with ResNet-18 using ImageNet pretrained weights. I froze all convolutional layers and trained only the final fully connected layer for 5 epochs on CIFAR-10. After training, I computed per-class metrics again. Overall accuracy for this transfer-learning model was also in the same range, but its cat precision and recall were still not clearly better than the class-weighted fine-tuned ResNet-18.

I created final comparison plots that show overall validation accuracy for the four models (baseline ResNet-18, fine-tuned ResNet-18, MobileNetV2, and transfer-learning ResNet-18) and a separate plot that shows cat precision and recall for each model. These plots make it easy to see that the class-weighted fine-tuned ResNet-18 gives the clearest improvement on the hardest class while keeping global performance stable.

Finally, I finished the documentation and reproducibility steps. I added detailed comments and docstrings in the notebook, organized the code into clear parts, and updated the README with an abstract, how-to-run instructions, and expected results. I also prepared a short slide deck summarizing the problem, methodology, and results and wrote a script to present the slides and the main notebook sections during the demo. At this point the project is complete and the code runs end-to-end from a fresh start with results that match the values I report.
